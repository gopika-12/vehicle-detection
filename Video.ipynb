{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze each frame of a video for cars using a pretrained Neural Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "import cv2\n",
    "import numpy as np\n",
    "from moviepy.editor import VideoFileClip\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage.measurements import label as scipyLabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = load_model('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/vehicles/3.png'\n",
    "image = cv2.imread(filename)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(model.predict(image[None, :, :, :], batch_size=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=(None, None), y_start_stop=(None, None), \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window_dim = 50\n",
    "class BigRect:\n",
    "    def __init__(self, window): # Window is in ((startx, starty), (endx, endy)) form\n",
    "        self.top_left = list(window[0])\n",
    "        self.bottom_right = list(window[1])\n",
    "\n",
    "    def add_rect(self, window):\n",
    "        \"\"\"Update the Big Rectangle Dimensions to include the small window\"\"\"\n",
    "        self.top_left[0] = min(self.top_left[0], window[0][0])\n",
    "        self.top_left[1] = min(self.top_left[1], window[0][1])\n",
    "        self.bottom_right[0] = max(self.bottom_right[0], window[1][0])\n",
    "        self.bottom_right[1] = max(self.bottom_right[1], window[1][1])\n",
    "    \n",
    "    def is_touching(self, window):\n",
    "        \"\"\"Determine if a sliding window should be added to the Big Rectangle\"\"\"\n",
    "        tmp_TL = [o-window_dim*0.7 for o in self.top_left]\n",
    "        tmp_BR = [o+window_dim*0.7 for o in self.bottom_right]\n",
    "        dx = min(self.bottom_right[0], window[1][0]) - max(self.top_left[0], window[0][0]) # Thanks stackoverflow\n",
    "        dy = min(self.bottom_right[1], window[1][1]) - max(self.top_left[1], window[0][1])\n",
    "        if (dx>=0) and (dy>=0):\n",
    "            return True\n",
    "        return False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def search_windows(img, windows):\n",
    "    big_rects = []\n",
    "    for window in windows:\n",
    "        small_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))\n",
    "        label = float(model.predict(small_img[None, :, :, :], batch_size=1))\n",
    "        if label > 0.7:\n",
    "            for big_rect in big_rects:\n",
    "                if big_rect.is_touching(window):\n",
    "                    big_rect.add_rect(window)\n",
    "                    break\n",
    "            else:\n",
    "                big_rects.append(BigRect(window))\n",
    "    return big_rects\n",
    "\n",
    "def add_heat(heatmap, prev_frames):    \n",
    "    for frame in prev_frames:\n",
    "        for big_rect in frame:\n",
    "            box = (big_rect.top_left, big_rect.bottom_right)\n",
    "            heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "            # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "h = 720\n",
    "w = 1280\n",
    "HIST_LEN = 20\n",
    "HEAT_THRESH = 10\n",
    "def process_image(img):\n",
    "    windows = []\n",
    "    windows += slide_window(img, (int(w*.6), w), (int(h*.5), int(h*.9)), xy_window=(window_dim,window_dim))\n",
    "    big_rects = search_windows(img, windows)\n",
    "    \n",
    "    # Update the history\n",
    "    prev_big_rects.append(big_rects) # List of lists\n",
    "    if len(prev_big_rects) > HIST_LEN: prev_big_rects.pop(0)\n",
    "    \n",
    "    # Create a heatmap over time to smooth the video\n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    heat = add_heat(heat, prev_big_rects)\n",
    "    heat = apply_threshold(heat, HEAT_THRESH)\n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    labels = scipyLabel(heatmap)\n",
    "    img_with_cars = draw_labeled_bboxes(np.copy(img), labels)\n",
    "\n",
    "    return img_with_cars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_big_rects = []\n",
    "\n",
    "output_file = 'output_images/video.mp4'\n",
    "# input_clip = VideoFileClip('project_video.mp4').subclip(27,35) # Subclip\n",
    "input_clip = VideoFileClip('project_video.mp4') # Full video\n",
    "output_clip = input_clip.fl_image(process_image) # NOTE: this function expects color images\n",
    "%time output_clip.write_videofile(output_file, audio=False)\n",
    "\n",
    "input_clip.reader.close()\n",
    "input_clip.audio.reader.close_proc()\n",
    "\n",
    "output_clip.reader.close()\n",
    "output_clip.audio.reader.close_proc()\n",
    "\n",
    "del input_clip\n",
    "del output_clip"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
